{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n2dSyboSFRR7",
    "outputId": "8da10d6f-d2a2-4ee0-919f-bce5171ec8f3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import joblib\n",
    "import sklearn.ensemble as ske \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree, linear_model\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Hp1p2lOkFWh6"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv', sep='|') #generate df as data\n",
    "X = data.drop(['Name', 'md5', 'legitimate'], axis=1).values #now droping some coloumns as axis 1(mean coloumn) and will show the values in the rows\n",
    "y = data['legitimate'].values #values of legitimate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-FfJbUM_Fok3",
    "outputId": "2cb57836-408f-4adc-a02a-39945d5a4830"
   },
   "outputs": [],
   "source": [
    "#print('Researching important feature based on %i total features\\n' % X.shape[1])# shape() is use in pandas to give number of row/column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn: Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, precision_recall_fscore_support, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"sklearn version = {sklearn.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection using Trees Classifier\n",
    "#### - ExtraTreesClassifier\n",
    "#### - RandomForestClassifier\n",
    "#### - DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "1L8yAxiuInm_"
   },
   "outputs": [],
   "source": [
    "#fsel= DecisionTreeClassifier(random_state=7)\n",
    "fsel= RandomForestClassifier(n_estimators=250, random_state=7)\n",
    "#fsel= ExtraTreesClassifier(n_estimators=250, random_state=7)\n",
    "\n",
    "fsel.fit(X,y)\n",
    "model = SelectFromModel(fsel, prefit=True)\n",
    "X_new = model.transform(X)\n",
    "nb_features = X_new.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "09c-w3X6Iqjz"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y ,test_size=0.3)#now converting in training and testing data in 20% range as total x is 138047 and testing is 138047*0.2=27610 :)\n",
    "features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V8_9xscMIxRe",
    "outputId": "e053fe2c-b630-4ca0-e5bb-262912229e00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 features identified as important:\n"
     ]
    }
   ],
   "source": [
    "print('%i features identified as important:' % nb_features) #as mentioned above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-fold cross-validation ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.993273658612304\n",
      "0.9926527655611321\n",
      "0.9947738797474904\n",
      "0.9927558729173135\n",
      "0.9939459795094691\n"
     ]
    }
   ],
   "source": [
    "fold_score = cross_val_score(fsel,X_train,y_train,cv=5,scoring=\"accuracy\")\n",
    "print(*fold_score, sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZE4HPHuXI6ys",
    "outputId": "a041b671-52c7-4d97-8e54-f656bff24c74",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. feature ImageBase (0.149219)\n",
      "2. feature SizeOfStackReserve (0.106221)\n",
      "3. feature MinorImageVersion (0.080523)\n",
      "4. feature VersionInformationSize (0.078188)\n",
      "5. feature ResourcesMinSize (0.076415)\n",
      "6. feature Characteristics (0.071597)\n",
      "7. feature MajorOperatingSystemVersion (0.052490)\n",
      "8. feature ExportNb (0.039770)\n",
      "9. feature Subsystem (0.033343)\n",
      "10. feature SectionsMaxEntropy (0.032934)\n",
      "11. feature ResourcesNb (0.031095)\n",
      "12. feature ResourcesMinEntropy (0.028490)\n",
      "13. feature DllCharacteristics (0.023797)\n"
     ]
    }
   ],
   "source": [
    "#important features sored\n",
    "indices = np.argsort(fsel.feature_importances_)[::-1][:nb_features]\n",
    "for f in range(nb_features):\n",
    "    print(\"%d. feature %s (%f)\" % (f + 1, data.columns[2+indices[f]], fsel.feature_importances_[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "9R0SCMRrI_WL"
   },
   "outputs": [],
   "source": [
    "# mean adding to the empty 'features' array the 'important features'\n",
    "for f in sorted(np.argsort(fsel.feature_importances_)[::-1][:nb_features]):#[::-1] mean start with last towards first \n",
    "    features.append(data.columns[2+f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now testing algorithms\n",
      "DecisionTree : 99.055898 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     67716\n",
      "           1       1.00      1.00      1.00     28916\n",
      "\n",
      "    accuracy                           1.00     96632\n",
      "   macro avg       1.00      1.00      1.00     96632\n",
      "weighted avg       1.00      1.00      1.00     96632\n",
      "\n",
      "RandomForest : 99.379452 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     67716\n",
      "           1       1.00      1.00      1.00     28916\n",
      "\n",
      "    accuracy                           1.00     96632\n",
      "   macro avg       1.00      1.00      1.00     96632\n",
      "weighted avg       1.00      1.00      1.00     96632\n",
      "\n",
      "GradientBoosting : 98.993118 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     67716\n",
      "           1       0.98      0.98      0.98     28916\n",
      "\n",
      "    accuracy                           0.99     96632\n",
      "   macro avg       0.99      0.99      0.99     96632\n",
      "weighted avg       0.99      0.99      0.99     96632\n",
      "\n",
      "AdaBoost : 98.560908 %\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     67716\n",
      "           1       0.98      0.97      0.98     28916\n",
      "\n",
      "    accuracy                           0.99     96632\n",
      "   macro avg       0.98      0.98      0.98     96632\n",
      "weighted avg       0.99      0.99      0.99     96632\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Algorithm comparison\n",
    "algorithms = {\n",
    "        \"DecisionTree\": tree.DecisionTreeClassifier(max_depth=100, random_state=7),\n",
    "    \n",
    "        \"RandomForest\": ske.RandomForestClassifier(n_estimators=100, random_state=777),\n",
    "    \n",
    "        \"GradientBoosting\": ske.GradientBoostingClassifier(n_estimators=100, random_state=777),\n",
    "        \"AdaBoost\": ske.AdaBoostClassifier(n_estimators=100, random_state=777),\n",
    "    }\n",
    "\n",
    "results = {}\n",
    "print(\"\\nNow testing algorithms\")\n",
    "for algo in algorithms:\n",
    "    clf = algorithms[algo]\n",
    "    clf.fit(X_train, y_train)\n",
    "    predicted = clf.predict(X_train)\n",
    "    #cm=confusion_matrix(y_train, predicted)   #Confusion Matrix\n",
    "    score = clf.score(X_test, y_test)\n",
    "    #plot_confusion_matrix(clf, X_train, y_train, cmap='Oranges')\n",
    "    print(\"%s : %f %%\" % (algo, score*100))\n",
    "    #print(metrics.confusion_matrix(y_test, predicted))\n",
    "    print(metrics.classification_report(y_train, predicted))\n",
    "    results[algo] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "6DKQefCOJIpH",
    "outputId": "91d7ef0a-9bdb-4667-d3d9-fb38aac97e6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Winner algorithm is RandomForest with a 99.379452 % success\n"
     ]
    }
   ],
   "source": [
    "winner = max(results, key=results.get)\n",
    "print('\\nWinner algorithm is %s with a %f %% success' % (winner, results[winner]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scikit-learn: confusion matrix\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "C_{0,0} & C_{0,1} \\\\\n",
    "C_{1,0} & C_{1,1}\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "tn&fp \\\\\n",
    "fn&tp\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "    <td></td>\n",
    "    <td>predicted false</td>\n",
    "    <td>predicted true</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>actual false</td>\n",
    "    <td>tn</td>\n",
    "    <td>fp</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td>actual true</td>\n",
    "    <td>fn</td>\n",
    "    <td>tp</td>\n",
    "</tr>\n",
    "<table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Accuracy={\\frac {{TP+TN} }{TP + TN +FP + FN} }\\\\\n",
    "Precision={\\frac {TP}{TP+FP}}\\\\\n",
    "Recall={\\frac {TP}{TP+FN}}\\\\\n",
    "F1 = 2 \\times {\\frac {precision \\times recall} {precision + recall}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cm = confusion_matrix(y_train, predicted)   #Confusion Matrix\n",
    "#plot_confusion_matrix(clf, X_train, y_train, cmap='Oranges')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the algorithm and the feature list for later predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "cA-Zn5BUJwtR",
    "outputId": "b2269b5e-b0f4-4237-dd19-3d6177f283c3"
   },
   "outputs": [],
   "source": [
    "#print('Saving algorithm and feature list in classifier directory...')\n",
    "#joblib.dump(algorithms[winner], 'classifier/classifier.pkl')\n",
    "#open('classifier/features.pkl', 'wb').write(pickle.dumps(features))\n",
    "#print('Saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify false and true positive rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "RgBDOa0zJ4Ft",
    "outputId": "34fca9fe-73d3-46db-dd46-2578e14b24b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False positive rate : 0.482625 %\n",
      "False negative rate : 0.943016 %\n"
     ]
    }
   ],
   "source": [
    "clf = algorithms[winner]\n",
    "res = clf.predict(X_test)\n",
    "mt = confusion_matrix(y_test, res)\n",
    "print(\"False positive rate : %f %%\" % ((mt[0][1] / float(sum(mt[0])))*100))\n",
    "print('False negative rate : %f %%' % ( (mt[1][0] / float(sum(mt[1]))*100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DIbrsaEdK4lP"
   },
   "source": [
    "### Computing AUROC and ROC curve values ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Learning_Notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
